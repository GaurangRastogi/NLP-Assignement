{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nat geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_doc(doc):\n",
    "    f = open(doc,\"r\", encoding='utf-8')\n",
    "    data = f.read()\n",
    "    word_tokens = word_tokenize(data)\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    filtered_sentence = []\n",
    "    stopwords_list = []\n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "        else:\n",
    "            stopwords_list.append(w)\n",
    "    \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = extract_doc(r\".\\article\\natgeo1.txt\")\n",
    "d2 = extract_doc(r\".\\article\\natgeo2.txt\")\n",
    "d3 = extract_doc(r\".\\article\\natgeo3.txt\")\n",
    "d4 = extract_doc(r\".\\article\\natgeo4.txt\")\n",
    "d5 = extract_doc(r\".\\article\\sample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_words = list(set(d1+d2+d3+d4+d5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tang',\n",
       " 'Yet',\n",
       " 'climbers',\n",
       " 'weathered',\n",
       " 'leaves',\n",
       " 'financial',\n",
       " 'documents',\n",
       " 'administering',\n",
       " 'geographic',\n",
       " 'patrolling',\n",
       " 'air',\n",
       " 'toppled',\n",
       " 'accounts',\n",
       " '2017',\n",
       " 'followed',\n",
       " 'receive',\n",
       " 'old',\n",
       " '“',\n",
       " 'mining',\n",
       " 'high',\n",
       " 'allowed',\n",
       " 'demographics',\n",
       " 'behavioral',\n",
       " 'endangered',\n",
       " 'term',\n",
       " 'economies',\n",
       " 'ants',\n",
       " 'becomes',\n",
       " 'data',\n",
       " 'individuals',\n",
       " 'roughly',\n",
       " 'fireflies',\n",
       " 'strength',\n",
       " 'catalogued',\n",
       " 'particularly',\n",
       " 'Brazil',\n",
       " 'prepare',\n",
       " 'deposited',\n",
       " 'maintained',\n",
       " 'money',\n",
       " 'Any',\n",
       " 'blended',\n",
       " 'culture',\n",
       " '1950',\n",
       " 'Hummingbirds',\n",
       " 'anomalies',\n",
       " 'computers',\n",
       " 'create',\n",
       " 'samples',\n",
       " 'Calanolide',\n",
       " '1968—were',\n",
       " 'Black',\n",
       " '?',\n",
       " 'remains',\n",
       " 'Can',\n",
       " 'eating',\n",
       " 'diet',\n",
       " 'extreme',\n",
       " 'megacity',\n",
       " 'locate',\n",
       " 'lives',\n",
       " 'equator',\n",
       " 'lowest',\n",
       " 'king',\n",
       " 'difference',\n",
       " 'words',\n",
       " 'Two',\n",
       " 'really',\n",
       " 'anomalies.',\n",
       " 'parents',\n",
       " 'Eridu',\n",
       " 'Antarctica',\n",
       " 'mitigate',\n",
       " 'Biston',\n",
       " 'BCD',\n",
       " 'aboard',\n",
       " 'six-year-olds',\n",
       " 'development',\n",
       " 'Or',\n",
       " 'shudder',\n",
       " 'south',\n",
       " 'forgotten',\n",
       " 'thousand',\n",
       " 'medicine',\n",
       " 'may',\n",
       " 'reef',\n",
       " 'Asia',\n",
       " 'yellow-tail',\n",
       " 'translation',\n",
       " 'Adventurer',\n",
       " 'SWP',\n",
       " 'tree',\n",
       " 'Dr.',\n",
       " 'sample',\n",
       " '1950s',\n",
       " 'issued',\n",
       " 'producing',\n",
       " 'fellow',\n",
       " 'organisms',\n",
       " 'pencil',\n",
       " 'forever',\n",
       " 'voluminous',\n",
       " 'verify',\n",
       " 'Sure',\n",
       " 'example',\n",
       " 'roof',\n",
       " 'insects',\n",
       " '2008',\n",
       " 'ecosystems',\n",
       " 'observations',\n",
       " 'sense',\n",
       " 'current',\n",
       " 'courage',\n",
       " 'system',\n",
       " 'observe',\n",
       " 'evil',\n",
       " 'past',\n",
       " 'correlate',\n",
       " 'mountainous',\n",
       " 'C.E',\n",
       " 'peaks',\n",
       " 'hiked',\n",
       " 'resemble',\n",
       " 'plan',\n",
       " 'project',\n",
       " 'segregation',\n",
       " 'scientist',\n",
       " 'dark',\n",
       " 'globe',\n",
       " 'exceptions',\n",
       " 'African',\n",
       " 'event',\n",
       " '2,174',\n",
       " 'Gearing',\n",
       " 'gather',\n",
       " 'offspring',\n",
       " 'plant',\n",
       " 'social',\n",
       " 'raining',\n",
       " 'womb',\n",
       " 'Indian',\n",
       " 'summer',\n",
       " 'seeds',\n",
       " 'resting',\n",
       " 'Malaysian',\n",
       " 'coffee',\n",
       " 'well',\n",
       " 'Structural',\n",
       " 'five',\n",
       " 'dive',\n",
       " 'drug',\n",
       " 'Kingdom',\n",
       " 'Fertile',\n",
       " '—from',\n",
       " 'awesome',\n",
       " 'kept',\n",
       " 'gently',\n",
       " 'family',\n",
       " 'legalized',\n",
       " 'competitive',\n",
       " 'coming',\n",
       " 'trends',\n",
       " 'Eric',\n",
       " 'discover',\n",
       " 'kind',\n",
       " 'marmots',\n",
       " 'quiet',\n",
       " 'fins',\n",
       " 'crashing',\n",
       " 'Huang',\n",
       " 'equipment',\n",
       " 'To',\n",
       " 'December',\n",
       " 'high-pitched',\n",
       " 'first',\n",
       " 'Corey',\n",
       " '41',\n",
       " 'famous',\n",
       " 'jobs',\n",
       " 'hunters',\n",
       " 'ate',\n",
       " 'called',\n",
       " 'estimated',\n",
       " 'develops',\n",
       " 'transport',\n",
       " 'slums—the',\n",
       " 'cream-colored',\n",
       " 'Middle',\n",
       " 'facilitated',\n",
       " 'reason',\n",
       " 'signal',\n",
       " 'opportunities',\n",
       " '(',\n",
       " 'cannons',\n",
       " 'experiences',\n",
       " 'connected',\n",
       " 'teaches',\n",
       " 'Democratic',\n",
       " 'moment—this',\n",
       " 'life',\n",
       " 'saltines',\n",
       " 'Up',\n",
       " '1800s',\n",
       " 'one',\n",
       " 'court',\n",
       " 'still',\n",
       " 'ensure',\n",
       " 'blossom',\n",
       " 'double-whammy',\n",
       " 'Past',\n",
       " 'For',\n",
       " 'lakes',\n",
       " 'Such',\n",
       " 'shot',\n",
       " '400',\n",
       " 'salt',\n",
       " 'puzzle.',\n",
       " 'ArcGIS',\n",
       " 'Service',\n",
       " 'expeditions',\n",
       " 'descend',\n",
       " 'Yellow',\n",
       " 'old-growth',\n",
       " 'declined',\n",
       " 'lost',\n",
       " 'wreck',\n",
       " 'History',\n",
       " 'adaptations',\n",
       " 'Paulo',\n",
       " 'Conservation',\n",
       " 'Spanish',\n",
       " 'specific',\n",
       " 'broad',\n",
       " 'four',\n",
       " 'unlike',\n",
       " 'Not',\n",
       " 'seeing',\n",
       " 'also',\n",
       " 'scree',\n",
       " 'recur',\n",
       " 'little',\n",
       " 'perseverance',\n",
       " 'spread',\n",
       " 'mimicry',\n",
       " 'early',\n",
       " 'black',\n",
       " 'always',\n",
       " 'legacies',\n",
       " 'happens',\n",
       " 'sound',\n",
       " 'transporting',\n",
       " 'focusing',\n",
       " 'communities',\n",
       " 'resulting',\n",
       " 'confined',\n",
       " 'temperature',\n",
       " 'information.',\n",
       " 'rising',\n",
       " 'region',\n",
       " 'sure.',\n",
       " 'real',\n",
       " 'Delhi',\n",
       " 'wrote',\n",
       " 'sensing',\n",
       " 'tiger',\n",
       " 'electric',\n",
       " 'first-descents',\n",
       " 'master',\n",
       " 'weights',\n",
       " 'So',\n",
       " 'Those',\n",
       " 'able',\n",
       " 'location',\n",
       " 'families',\n",
       " '1827',\n",
       " 'see',\n",
       " 'Buoyancy',\n",
       " 'robotics',\n",
       " 'infections',\n",
       " 'meats',\n",
       " 'carry',\n",
       " 'pins',\n",
       " 'millions',\n",
       " 'children—were',\n",
       " 'Nerd',\n",
       " 'fight',\n",
       " 'ruse',\n",
       " 'slow',\n",
       " 'Adevnture',\n",
       " 'calves',\n",
       " 'oil',\n",
       " 'drowned',\n",
       " 'exciting',\n",
       " 'hand',\n",
       " 'listen',\n",
       " 'mimic',\n",
       " 'physical',\n",
       " 'pika',\n",
       " 'decline',\n",
       " 'bone',\n",
       " 'balls',\n",
       " 'Trail',\n",
       " 'Catch',\n",
       " 'workers',\n",
       " 'Both',\n",
       " 'hummingbirds',\n",
       " 'National',\n",
       " 'reintroducing',\n",
       " 'Behavioral',\n",
       " 'pregnancy',\n",
       " 'ballast',\n",
       " 'addition',\n",
       " 'fasteners',\n",
       " 'vacations',\n",
       " 'descent',\n",
       " 'looking',\n",
       " 'As',\n",
       " 'Culture',\n",
       " 'land',\n",
       " 'bears',\n",
       " 'making',\n",
       " 'faced',\n",
       " 'Tell',\n",
       " 'raw',\n",
       " 'Loss',\n",
       " 'points',\n",
       " 'conversations',\n",
       " 'enough',\n",
       " 'future',\n",
       " 'emergent',\n",
       " 'prologue.',\n",
       " 'limit',\n",
       " 'decades',\n",
       " 'While',\n",
       " 'Ring',\n",
       " 'resources',\n",
       " 'policies',\n",
       " 'pika—an',\n",
       " '2019',\n",
       " 'animals',\n",
       " 'taking',\n",
       " 'spotted',\n",
       " 'upper',\n",
       " 'Sailing',\n",
       " 'Bureau',\n",
       " 'transportation',\n",
       " 'finding',\n",
       " 'suggest',\n",
       " 'Florida',\n",
       " 'deadly',\n",
       " 'casualty',\n",
       " 'moving',\n",
       " 'hoping',\n",
       " 'bought',\n",
       " 'important',\n",
       " 'stride',\n",
       " 'forget',\n",
       " 'Benefits',\n",
       " 'connected—by',\n",
       " 'scene',\n",
       " '2050',\n",
       " 'tell',\n",
       " 'ruler',\n",
       " '12-pounders',\n",
       " 'layers',\n",
       " 'lasted',\n",
       " 'Trade',\n",
       " 'others',\n",
       " 'Lasting',\n",
       " 'carries',\n",
       " 'rural',\n",
       " 'farms',\n",
       " 'company',\n",
       " 'Administration',\n",
       " 'specialized',\n",
       " 'fragments',\n",
       " 'copy',\n",
       " 'wolverine',\n",
       " 'governed',\n",
       " 'materials',\n",
       " 'want',\n",
       " 'positively',\n",
       " '60',\n",
       " 'agoutis',\n",
       " 'carried',\n",
       " 'greatest',\n",
       " 'programming',\n",
       " 'ship-wrecking',\n",
       " 'hummingbird',\n",
       " 'decimal',\n",
       " 'stood',\n",
       " 'voice',\n",
       " 'mountains',\n",
       " 'provided',\n",
       " 'My',\n",
       " 'Jim',\n",
       " 'going',\n",
       " 'gear',\n",
       " 'institutions',\n",
       " 'increase',\n",
       " 'top',\n",
       " 'distributed',\n",
       " 'legs',\n",
       " 'certifications',\n",
       " 'throughout',\n",
       " 'Placental',\n",
       " 'China',\n",
       " 'Slavery',\n",
       " 'landscapes',\n",
       " 'Andes',\n",
       " 'Sugar',\n",
       " 'Atmospheric',\n",
       " 'Adaptations',\n",
       " 'upon',\n",
       " 'Indigenous',\n",
       " 'subcontinent',\n",
       " 'niche',\n",
       " 'biologist',\n",
       " 'corners',\n",
       " 'average',\n",
       " 'laws—active',\n",
       " 'absolutely',\n",
       " 'tropical',\n",
       " 'discovered',\n",
       " 'rabbit',\n",
       " 'carefully',\n",
       " '7,800',\n",
       " 'Phascolarctos',\n",
       " 'chained',\n",
       " 'Finding',\n",
       " 'grown',\n",
       " 'carbon',\n",
       " 'potential',\n",
       " 'challenge',\n",
       " 'algae',\n",
       " 'wildlife—in',\n",
       " 'Few',\n",
       " 'cities',\n",
       " 'extract',\n",
       " 'rainforests',\n",
       " 'expedition',\n",
       " 'Egypt',\n",
       " 'hear',\n",
       " 'subsequently',\n",
       " 'smaller',\n",
       " 'Protection',\n",
       " 'MacMurray',\n",
       " 'fits',\n",
       " 'humid',\n",
       " 'owner',\n",
       " 'Rome',\n",
       " 'open',\n",
       " 'emit',\n",
       " 'record',\n",
       " 'species',\n",
       " 'peppered',\n",
       " 'steady',\n",
       " 'warm',\n",
       " 'former',\n",
       " 'experienced',\n",
       " 'disturbances',\n",
       " 'outreach',\n",
       " 'cultivate',\n",
       " 'Indonesia',\n",
       " 'inadvertently',\n",
       " 'established',\n",
       " 'Institution',\n",
       " 'Shakespeare',\n",
       " 'planting',\n",
       " 'love',\n",
       " 'knowing',\n",
       " 'totally',\n",
       " 'midlatitudes',\n",
       " ',',\n",
       " 'essential',\n",
       " 'gliding',\n",
       " 'construct.',\n",
       " 'trails',\n",
       " '2030',\n",
       " 'developing',\n",
       " 'joined',\n",
       " 'Shipwreck',\n",
       " 'endangering',\n",
       " 'enslaved',\n",
       " 'palm',\n",
       " 'another',\n",
       " 'shrimp',\n",
       " 'play',\n",
       " 'happen',\n",
       " 'sold',\n",
       " 'Topher',\n",
       " 'hundreds',\n",
       " 'services',\n",
       " 'traffic',\n",
       " 'born',\n",
       " 'state',\n",
       " 'build',\n",
       " 'critical',\n",
       " 'elk',\n",
       " 'Explorer',\n",
       " 'explain',\n",
       " 'history—the',\n",
       " 'Illinois',\n",
       " 'sure',\n",
       " 'habits',\n",
       " 'race',\n",
       " 'crime',\n",
       " 'reasons',\n",
       " 'water',\n",
       " 'storage',\n",
       " 'Census',\n",
       " 'anywhere.',\n",
       " 'fill',\n",
       " 'City',\n",
       " 'human-caused',\n",
       " 'take',\n",
       " 'society',\n",
       " '16th',\n",
       " 'São',\n",
       " 'gun',\n",
       " 'Who',\n",
       " 'safety',\n",
       " 'Our',\n",
       " 'sea',\n",
       " 'use',\n",
       " 'roads',\n",
       " 'different',\n",
       " 'War',\n",
       " 'Driven',\n",
       " 'went',\n",
       " 'say',\n",
       " 'floor',\n",
       " 'breaths',\n",
       " 'including',\n",
       " 'moth',\n",
       " 'answering',\n",
       " 'surrender',\n",
       " 'prompted',\n",
       " 'Uruk',\n",
       " 'Study',\n",
       " 'reference',\n",
       " 'Ironically',\n",
       " 'increase—that',\n",
       " 'flatfish',\n",
       " 'drawn',\n",
       " 'pirated',\n",
       " 'resource',\n",
       " 'food',\n",
       " 'Geographic',\n",
       " 'large-scale',\n",
       " 'enduring',\n",
       " 'Organizations',\n",
       " 'forests',\n",
       " 'rates',\n",
       " 'deep',\n",
       " 'One',\n",
       " 'parrot',\n",
       " 'camp',\n",
       " 'trade',\n",
       " 'Part',\n",
       " 'evolved',\n",
       " 'archaeologists',\n",
       " 'author',\n",
       " 'megacities',\n",
       " 'radiation',\n",
       " 'foundation',\n",
       " 'Google',\n",
       " 'ton',\n",
       " 'Global',\n",
       " 'orchids',\n",
       " 'responsible',\n",
       " 'In',\n",
       " 'continent',\n",
       " 'falling',\n",
       " 'tacks',\n",
       " 'artifact',\n",
       " 'Dive',\n",
       " 'Thaumoctopus',\n",
       " 'useless',\n",
       " 'Grey',\n",
       " 'like',\n",
       " 'sustainable',\n",
       " 'demand',\n",
       " 'speciation',\n",
       " 'partly',\n",
       " 'stabilize',\n",
       " 'hard',\n",
       " 'recognized',\n",
       " 'commodities—something',\n",
       " 'feeding',\n",
       " 'considerably',\n",
       " 'advantageous',\n",
       " 'among',\n",
       " 'format',\n",
       " 'war',\n",
       " '5.4',\n",
       " 'darker',\n",
       " 'amounts',\n",
       " 'contributes',\n",
       " 'disputes',\n",
       " 'post-Civil',\n",
       " 'allow',\n",
       " 'right',\n",
       " 'named',\n",
       " 'economic',\n",
       " 'Matters',\n",
       " 'creating',\n",
       " 'Sympatric',\n",
       " 'institutional',\n",
       " 'key',\n",
       " 'collective',\n",
       " 'member',\n",
       " '200',\n",
       " 'hero',\n",
       " 'giant',\n",
       " 'hold',\n",
       " '35,000',\n",
       " 'London',\n",
       " 'Mongolia',\n",
       " 'wanderer',\n",
       " 'Straits',\n",
       " 'empty',\n",
       " 'human',\n",
       " 'Thylacinus',\n",
       " 'greenhouse',\n",
       " 'jellyfish',\n",
       " 'records',\n",
       " 'Certain',\n",
       " 'Italy',\n",
       " 'quality',\n",
       " 'massive',\n",
       " 'affecting',\n",
       " 'feathers',\n",
       " 'filled',\n",
       " 'seven',\n",
       " 'Although',\n",
       " 'surpass',\n",
       " ')',\n",
       " 'bar',\n",
       " 'path.',\n",
       " 'regulator',\n",
       " 'worms',\n",
       " 'largely',\n",
       " 'Gail',\n",
       " 'keep',\n",
       " 'within',\n",
       " 'could',\n",
       " 'anthers',\n",
       " 'thought',\n",
       " 'provides',\n",
       " 'Coadaptation',\n",
       " 'explorers',\n",
       " 'night',\n",
       " 'equipped',\n",
       " 'industrial',\n",
       " 'ancestors',\n",
       " 'urban',\n",
       " 'logging',\n",
       " 'city',\n",
       " 'nature',\n",
       " 'house',\n",
       " 'textiles',\n",
       " 'Tokyo',\n",
       " 'sometimes',\n",
       " 'Marsupials',\n",
       " 'Africans—men',\n",
       " 'send',\n",
       " 'shipwreck',\n",
       " 'Amazonian',\n",
       " 'efforts',\n",
       " '19th',\n",
       " 'moths',\n",
       " 'decaying',\n",
       " 'Bolivar',\n",
       " 'underwater',\n",
       " 'offices',\n",
       " 'done',\n",
       " 'regulating',\n",
       " 'research',\n",
       " 'sank…the',\n",
       " 'ArcMap',\n",
       " 'thimble',\n",
       " 'Matter',\n",
       " 'Despite',\n",
       " 'contain',\n",
       " 'fitness',\n",
       " 'flight',\n",
       " 'grow',\n",
       " 'run',\n",
       " 'And',\n",
       " 'believes',\n",
       " 'That',\n",
       " 'place',\n",
       " 'Many',\n",
       " 'fields',\n",
       " 'Evidence',\n",
       " 'conservation',\n",
       " 'Settling',\n",
       " 'Atlantic',\n",
       " 'snapper',\n",
       " 'Urban',\n",
       " 'fall',\n",
       " 'pollen',\n",
       " 'sends',\n",
       " 'Feathers',\n",
       " 'minutes',\n",
       " 'mission',\n",
       " 'attempted',\n",
       " 'fish',\n",
       " 'iron',\n",
       " 'six',\n",
       " 'Amendment',\n",
       " 'steadily',\n",
       " 'settle',\n",
       " 'much-needed',\n",
       " 'engaged',\n",
       " 'kilometers',\n",
       " 'Africa',\n",
       " 'These',\n",
       " 'every',\n",
       " 'endured',\n",
       " 'collection',\n",
       " 'two-thirds',\n",
       " 'using',\n",
       " 'guns',\n",
       " 'prospered',\n",
       " 'stiffer',\n",
       " 'sworn',\n",
       " 'perverse',\n",
       " 'survey',\n",
       " 'identify',\n",
       " 'prevalent',\n",
       " 'Shanghai',\n",
       " 'nowadays',\n",
       " 'Stewardship',\n",
       " 'big',\n",
       " 'downsides',\n",
       " 'tourism',\n",
       " 'investigated',\n",
       " 'beneficial',\n",
       " 'put',\n",
       " 'lose',\n",
       " 'ships',\n",
       " 'working',\n",
       " 'smoothly',\n",
       " 'BCDs',\n",
       " 'center',\n",
       " 'Pacific',\n",
       " 'animal',\n",
       " 'upward',\n",
       " 'cats',\n",
       " 'rare',\n",
       " 'geography',\n",
       " 'nearly',\n",
       " 'Crescent',\n",
       " 'functionless',\n",
       " 'reduced',\n",
       " 'rather',\n",
       " 'cinereus',\n",
       " 'First',\n",
       " 'mostly',\n",
       " 'ratification',\n",
       " 'visualize',\n",
       " 'behavior',\n",
       " 'specifically',\n",
       " 'variety',\n",
       " 'evils',\n",
       " 'remember',\n",
       " 'rigorous',\n",
       " 'Douglass',\n",
       " 'cities—as',\n",
       " 'middle',\n",
       " 'Schlosberg',\n",
       " 'anti-cancer',\n",
       " 'vegetation',\n",
       " 'captain',\n",
       " 'spices',\n",
       " 'refers',\n",
       " 'primarily',\n",
       " 'sit',\n",
       " 'mind',\n",
       " 'meet',\n",
       " 'rate',\n",
       " 'boat',\n",
       " 'Without',\n",
       " 'urbanization',\n",
       " 'determined',\n",
       " '50',\n",
       " 'engrossed',\n",
       " '[',\n",
       " 'relatively',\n",
       " 'surface',\n",
       " 'role',\n",
       " 'University',\n",
       " 'movements',\n",
       " 'dropped',\n",
       " 'number',\n",
       " 'shallow',\n",
       " 'tied',\n",
       " 'china',\n",
       " 'additional',\n",
       " 'afterward',\n",
       " 'forms',\n",
       " 'Arctic',\n",
       " 'terror',\n",
       " 'Nigeria',\n",
       " 'Treinish',\n",
       " 'women',\n",
       " 'many',\n",
       " 'scientists',\n",
       " 'plank',\n",
       " 'vestigial',\n",
       " 'smallest',\n",
       " 'expected',\n",
       " 'battle',\n",
       " 'percent',\n",
       " 'hover',\n",
       " 'claims',\n",
       " '3,500',\n",
       " 'Lives',\n",
       " 'Ivoire',\n",
       " 'millennia',\n",
       " 'estimate',\n",
       " 'common',\n",
       " 'time',\n",
       " 'careful',\n",
       " 'sports',\n",
       " 'strong',\n",
       " 'buddies',\n",
       " 'tigers',\n",
       " 'hardships',\n",
       " 'visit',\n",
       " 'items',\n",
       " 'laugh',\n",
       " 'gives',\n",
       " 'there.',\n",
       " 'point',\n",
       " 'distance',\n",
       " 'item',\n",
       " 'rivers',\n",
       " 'attribute',\n",
       " 'red',\n",
       " 'almost',\n",
       " 'delivering',\n",
       " 'Way',\n",
       " 'growing',\n",
       " 'Human',\n",
       " 'Work',\n",
       " 'longer',\n",
       " 'Weapons',\n",
       " 'appearance',\n",
       " 'England',\n",
       " 'opposite',\n",
       " '’',\n",
       " 'places',\n",
       " 'asking',\n",
       " 'triangle',\n",
       " 'nations',\n",
       " 'source',\n",
       " 'rise',\n",
       " 'remembers',\n",
       " 'Slave',\n",
       " 'mankind',\n",
       " 'crimes',\n",
       " 'road',\n",
       " 'measurements',\n",
       " 'Typically',\n",
       " 'Why',\n",
       " 'lucrative',\n",
       " 'beauty',\n",
       " 'Wildlife',\n",
       " 'study',\n",
       " 'protected',\n",
       " 'so-called',\n",
       " 'team',\n",
       " 'slavers',\n",
       " 'clearly',\n",
       " 'trying',\n",
       " 'located',\n",
       " 'recycled',\n",
       " 'surpluses',\n",
       " 'taken',\n",
       " 'Australia',\n",
       " 'around',\n",
       " '2003',\n",
       " 'hit',\n",
       " 'splits',\n",
       " 'discussions',\n",
       " 'ran',\n",
       " 'better',\n",
       " 'snakes',\n",
       " 'North',\n",
       " 'nut',\n",
       " 'become',\n",
       " 'network',\n",
       " 'densities',\n",
       " 'adapt',\n",
       " 'transpiration',\n",
       " 'José',\n",
       " 'share',\n",
       " 'Even',\n",
       " 'claim',\n",
       " 'agony',\n",
       " 'darker-colored',\n",
       " 'fact',\n",
       " 'Swanson',\n",
       " '19',\n",
       " 'Andes.',\n",
       " 'York',\n",
       " 'DWP',\n",
       " 'adapted',\n",
       " 'spurring',\n",
       " 'Each',\n",
       " 'atmosphere',\n",
       " 'speed',\n",
       " 'factories',\n",
       " 'caught',\n",
       " 'Diving',\n",
       " 'even',\n",
       " '10',\n",
       " 'collect',\n",
       " 'existed',\n",
       " 'signs',\n",
       " 'forces',\n",
       " 'houses',\n",
       " 'overlay',\n",
       " 'predicted',\n",
       " 'develop',\n",
       " 'Indus',\n",
       " 'later',\n",
       " 'wildlife',\n",
       " 'defy',\n",
       " 'cannon',\n",
       " 'past—helps',\n",
       " 'Go',\n",
       " 'struggling',\n",
       " 'stripes',\n",
       " 'industrialized',\n",
       " 'River',\n",
       " 'approaching',\n",
       " 'Here',\n",
       " 'ever-larger',\n",
       " 'Borneo',\n",
       " 'helps',\n",
       " 'kilograms',\n",
       " 'birth',\n",
       " 'slave',\n",
       " 'blue',\n",
       " 'great',\n",
       " 'battle.',\n",
       " 'But',\n",
       " 'death',\n",
       " 'drugs',\n",
       " 'closer',\n",
       " 'getting',\n",
       " 'ranching',\n",
       " 'Remember',\n",
       " '”',\n",
       " 'Museum',\n",
       " 'He',\n",
       " 'relationship',\n",
       " '12,553',\n",
       " 'topped',\n",
       " 'prior',\n",
       " 'gauge',\n",
       " 'Cuba',\n",
       " 'India',\n",
       " 'confront',\n",
       " 'temperatures',\n",
       " 'residents',\n",
       " '2',\n",
       " 'We',\n",
       " 'They',\n",
       " 'manifests',\n",
       " 'Europe',\n",
       " 'schooner-of-war',\n",
       " 'longest',\n",
       " 'shipwrecked',\n",
       " 'several',\n",
       " 'Found',\n",
       " 'Japan',\n",
       " 'recently',\n",
       " 'canyons',\n",
       " 'resolve',\n",
       " 'skied',\n",
       " 'pollution',\n",
       " 'pollinated',\n",
       " '17',\n",
       " 'deposition',\n",
       " 'spots',\n",
       " 'combed',\n",
       " \"'s\",\n",
       " 'sections',\n",
       " 'got',\n",
       " '12-pounder',\n",
       " 'care',\n",
       " 'maritime',\n",
       " 'ask',\n",
       " 'everybody',\n",
       " 'crops',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of distinct words\n",
    "distinct_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        words  d1  d2  d3  d4  d5\n",
      "0        tang   0   0   1   0   0\n",
      "1         Yet   0   0   2   0   0\n",
      "2    climbers   1   0   0   0   0\n",
      "3   weathered   1   0   0   0   0\n",
      "4      leaves   0   0   0   1   1\n",
      "..        ...  ..  ..  ..  ..  ..\n",
      "95     issued   0   0   1   0   0\n",
      "96  producing   0   0   0   0   1\n",
      "97     fellow   1   0   0   0   0\n",
      "98  organisms   0   0   0   3   0\n",
      "99     pencil   0   0   1   0   0\n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#Bag of Words representation\n",
    "import pandas as pd\n",
    "\n",
    "def Bag_of_words(word_list):\n",
    "    word_l = []\n",
    "    for word in distinct_words:\n",
    "        if (word in word_list) == True:\n",
    "            word_l.append(word_list.count(word))\n",
    "        else:\n",
    "            word_l.append(0)\n",
    "        \n",
    "    return word_l\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"words\"] = distinct_words\n",
    "df[\"d1\"] = Bag_of_words(d1)\n",
    "df[\"d2\"] = Bag_of_words(d2)\n",
    "df[\"d3\"] = Bag_of_words(d3)\n",
    "df[\"d4\"] = Bag_of_words(d4)\n",
    "df[\"d5\"] = Bag_of_words(d5)\n",
    "\n",
    "    \n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              words   d1   d2        d3   d4        d5\n",
      "0              tang  0.0  0.0  1.000000  0.0  0.000000\n",
      "1               Yet  0.0  0.0  1.526589  0.0  0.000000\n",
      "2          climbers  1.0  0.0  0.000000  0.0  0.000000\n",
      "3         weathered  1.0  0.0  0.000000  0.0  0.000000\n",
      "4            leaves  0.0  0.0  0.000000  1.0  1.000000\n",
      "...             ...  ...  ...       ...  ...       ...\n",
      "2052         corals  0.0  0.0  1.000000  0.0  0.000000\n",
      "2053  nutrient-rich  0.0  0.0  0.000000  1.0  0.000000\n",
      "2054       magnetic  0.0  0.0  1.000000  0.0  0.000000\n",
      "2055         canopy  0.0  0.0  0.000000  0.0  1.869742\n",
      "2056        heavily  0.0  0.0  1.000000  0.0  0.000000\n",
      "\n",
      "[2057 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def TF(word_list):\n",
    "    word_l = []\n",
    "    for word in distinct_words:\n",
    "        if (word in word_list) == True:\n",
    "            word_l.append(1+math.log(1+math.log(word_list.count(word))))\n",
    "        else:\n",
    "            word_l.append(0)\n",
    "        \n",
    "    return word_l\n",
    "\n",
    "tf = pd.DataFrame()\n",
    "tf[\"words\"] = distinct_words\n",
    "tf[\"d1\"] = TF(d1)\n",
    "tf[\"d2\"] = TF(d2)\n",
    "tf[\"d3\"] = TF(d3)\n",
    "tf[\"d4\"] = TF(d4)\n",
    "tf[\"d5\"] = TF(d5)\n",
    "    \n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               word  relevance\n",
      "0              tang   1.791759\n",
      "1               Yet   1.791759\n",
      "2          climbers   1.791759\n",
      "3         weathered   1.791759\n",
      "4            leaves   1.252763\n",
      "...             ...        ...\n",
      "2052         corals   1.791759\n",
      "2053  nutrient-rich   1.791759\n",
      "2054       magnetic   1.791759\n",
      "2055         canopy   1.791759\n",
      "2056        heavily   1.791759\n",
      "\n",
      "[2057 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "idf = pd.DataFrame()\n",
    "\n",
    "def IDF():\n",
    "    l = []\n",
    "    D = [d1,d2,d3,d4,d5]\n",
    "    for i in distinct_words:\n",
    "        d = 0\n",
    "        for j in D:\n",
    "            if i in j:\n",
    "                d+=1\n",
    "                \n",
    "        l.append(math.log(1+5/d))\n",
    "        \n",
    "    return l\n",
    "        \n",
    "idf[\"word\"] = distinct_words\n",
    "idf[\"relevance\"] = IDF()\n",
    "\n",
    "        \n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              words        d1   d2        d3        d4        d5\n",
      "0              tang  0.000000  0.0  1.791759  0.000000  0.000000\n",
      "1               Yet  0.000000  0.0  2.735280  0.000000  0.000000\n",
      "2          climbers  1.791759  0.0  0.000000  0.000000  0.000000\n",
      "3         weathered  1.791759  0.0  0.000000  0.000000  0.000000\n",
      "4            leaves  0.000000  0.0  0.000000  1.252763  1.252763\n",
      "...             ...       ...  ...       ...       ...       ...\n",
      "2052         corals  0.000000  0.0  1.791759  0.000000  0.000000\n",
      "2053  nutrient-rich  0.000000  0.0  0.000000  1.791759  0.000000\n",
      "2054       magnetic  0.000000  0.0  1.791759  0.000000  0.000000\n",
      "2055         canopy  0.000000  0.0  0.000000  0.000000  3.350127\n",
      "2056        heavily  0.000000  0.0  1.791759  0.000000  0.000000\n",
      "\n",
      "[2057 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tfidf = pd.DataFrame()\n",
    "tfidf[\"words\"] = distinct_words\n",
    "\n",
    "n1 = np.array(tf.d1)\n",
    "n2 = np.array(tf.d2)\n",
    "n3 = np.array(tf.d3)\n",
    "n4 = np.array(tf.d4)\n",
    "n5 = np.array(tf.d5)\n",
    "x = np.array(idf.relevance)\n",
    "\n",
    "tfidf[\"d1\"] = n1*x\n",
    "tfidf[\"d2\"] = n2*x\n",
    "tfidf[\"d3\"] = n3*x\n",
    "tfidf[\"d4\"] = n4*x\n",
    "tfidf[\"d5\"] = n5*x\n",
    "\n",
    "print(tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              words        d1   d2        d3        d4        d5\n",
      "0              tang  0.000000  0.0  0.000871  0.000000  0.000000\n",
      "1               Yet  0.000000  0.0  0.001330  0.000000  0.000000\n",
      "2          climbers  0.000871  0.0  0.000000  0.000000  0.000000\n",
      "3         weathered  0.000871  0.0  0.000000  0.000000  0.000000\n",
      "4            leaves  0.000000  0.0  0.000000  0.000609  0.000609\n",
      "...             ...       ...  ...       ...       ...       ...\n",
      "2052         corals  0.000000  0.0  0.000871  0.000000  0.000000\n",
      "2053  nutrient-rich  0.000000  0.0  0.000000  0.000871  0.000000\n",
      "2054       magnetic  0.000000  0.0  0.000871  0.000000  0.000000\n",
      "2055         canopy  0.000000  0.0  0.000000  0.000000  0.001629\n",
      "2056        heavily  0.000000  0.0  0.000871  0.000000  0.000000\n",
      "\n",
      "[2057 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#normalized tf-idf for docs\n",
    "tfidf.d1/=len(distinct_words)\n",
    "tfidf.d2/=len(distinct_words)\n",
    "tfidf.d3/=len(distinct_words)\n",
    "tfidf.d4/=len(distinct_words)\n",
    "tfidf.d5/=len(distinct_words)\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d1': 0.069680134, 'd2': 0.0742463825, 'd3': 0.0693066194, 'd4': 0.0754373953}\n"
     ]
    }
   ],
   "source": [
    "#cosine-similarity\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "cs = {}\n",
    "q = 0\n",
    "for i in np.array(tfidf.d5):\n",
    "    q+=(i**2)\n",
    "    \n",
    "# print(q)\n",
    "\n",
    "def cosine_sim(doc):\n",
    "    d = 0\n",
    "    for i in doc:\n",
    "        d+=(i**2) \n",
    "        \n",
    "#     print(d)\n",
    "    a = doc.dot(np.array(tfidf.d5))\n",
    "#     print(a)\n",
    "#     return (a/(math.sqrt(q*d)))\n",
    "    return('{0:.10f}'.format((a/(math.sqrt(q*d)))))\n",
    "\n",
    "cs[\"d1\"] = float(cosine_sim(np.array(tfidf.d1)))\n",
    "cs[\"d2\"] = float(cosine_sim(np.array(tfidf.d2)))\n",
    "cs[\"d3\"] = float(cosine_sim(np.array(tfidf.d3)))\n",
    "cs[\"d4\"] = float(cosine_sim(np.array(tfidf.d4)))\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#document ranking\n",
    "def rank_doc(array):\n",
    "    l = array.copy()\n",
    "    valid = True\n",
    "    while valid:\n",
    "#         print(l)\n",
    "        if(len(np.where(array == max(l))[0]) > 1):\n",
    "            for i in range(len(np.where(array == max(l))[0])):\n",
    "                print((np.where(array == max(l))[0][i]+1),)\n",
    "            l = np.delete(l,np.where(l == max(l)),0)\n",
    "        else:\n",
    "            print(np.where(array == max(l))[0][0]+1)\n",
    "            l = np.delete(l,np.where(l == max(l))[0],0)\n",
    "            \n",
    "        if(len(l) == 0):\n",
    "            valid = False\n",
    "            \n",
    "\n",
    "rank_doc(np.array(list(cs.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d1': 0.0254319013, 'd2': 0.0229915079, 'd3': 0.0336028548, 'd4': 0.0237854093}\n",
      "[0.0254319013, 0.0229915079, 0.0336028548, 0.0237854093]\n",
      "2\n",
      "4\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#Euclidean Distance and Document Ranking\n",
    "ed = {}\n",
    "def euc_d(doc,query):\n",
    "    e = 0\n",
    "    for i in range(len(doc)):\n",
    "        e+=(doc[i] - query[i])**2\n",
    "        \n",
    "    return ('{0:.10f}'.format(math.sqrt(e)))\n",
    "        \n",
    "ed[\"d1\"] = float(euc_d(np.array(tfidf.d1), np.array(tfidf.d5)))\n",
    "ed[\"d2\"] = float(euc_d(np.array(tfidf.d2), np.array(tfidf.d5)))\n",
    "ed[\"d3\"] = float(euc_d(np.array(tfidf.d3), np.array(tfidf.d5)))\n",
    "ed[\"d4\"] = float(euc_d(np.array(tfidf.d4), np.array(tfidf.d5)))\n",
    "print(ed)\n",
    "print(list(ed.values()))\n",
    "\n",
    "def rank_doc(array):\n",
    "    l = array.copy()\n",
    "    valid = True\n",
    "    while valid:\n",
    "        if(len(np.where(array == min(l))[0]) > 1):\n",
    "            for i in range(len(np.where(array == min(l))[0])):\n",
    "                print((np.where(array == min(l))[0][i]+1),)\n",
    "            l = np.delete(l,np.where(l == min(l)),0)\n",
    "        else:\n",
    "            print(np.where(array == min(l))[0][0]+1)\n",
    "            l = np.delete(l,np.where(l == min(l))[0],0)\n",
    "            \n",
    "        if(len(l) == 0):\n",
    "            valid = False\n",
    "\n",
    "            \n",
    "\n",
    "rank_doc(np.array(list(ed.values())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Note - we see that after computing the cosine similarity and Eucledian distance between the sample article and the 4 articles given to us in the form of the corpus, the similarity is almost negligible.\n",
    "Hence it is safe to assume that the articles she writes are original and we can hire her for our publication.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
