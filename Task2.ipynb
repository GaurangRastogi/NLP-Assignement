{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d09084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2 \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ace54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "027a46ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 4, 'to': 2, 'branch': 2, 'of': 2, 'Natural': 1, 'language': 1, 'processing': 1, '(NLP)': 1, 'refers': 1, 'computer': 1, ...})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequency Distribution of Words\n",
    "import nltk\n",
    "text1=\"Natural language processing (NLP) refers to the branch of computer science—and more specifically, the branch of artificial intelligence or AI—concerned with giving computers the ability to understand text and spoken words in much the same way human beings can.\"\n",
    "fd=nltk.FreqDist(text1.split())\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e68352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'more': 1, 'with': 1, 'text': 1, 'much': 1, 'same': 1, 'can.': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import  ConditionalFreqDist\n",
    "cfd=ConditionalFreqDist((len(word),word) for word in text1.split())\n",
    "cfd[4] #gives you four words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c97893aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To determine Frequency Distribution and Conditional Frequency Distribution of any one of the Presidential inaugural address\n",
    "# (nouns -> business not adjective)\n",
    "# Try to get frequency distribution (histograms) from any of the president speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efd8209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jieba -> since cjk(chinese japenese korean) doesn't have word boundary, we can install jieba which will give word boundaries to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e08d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c56637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\GAURAN~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.815 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "影印 影印本 印本 重 複\n"
     ]
    }
   ],
   "source": [
    "#Chinese Segmentation using jieba\n",
    "import jieba\n",
    "seg= jieba.cut(\"影印本重複\",cut_all=True);\n",
    "print(\" \".join(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "088de6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Become', 'an', 'expert', 'in', 'NLP']\n"
     ]
    }
   ],
   "source": [
    "#Task -> Basic Text Processing Pipeline\n",
    "import nltk\n",
    "sent=\"Become an expert in NLP\"\n",
    "words=nltk.word_tokenize(sent)  #splitting of words -> no difference between split() and word_tokenize()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8b38bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'refers', 'to', 'the', 'branch', 'of', 'computer', 'science—and', 'more', 'specifically', ',', 'the', 'branch', 'of', 'artificial', 'intelligence', 'or', 'AI—concerned', 'with', 'giving', 'computers', 'the', 'ability', 'to', 'understand', 'text', 'and', 'spoken', 'words', 'in', 'much', 'the', 'same', 'way', 'human', 'beings', 'can', '.']\n"
     ]
    }
   ],
   "source": [
    "texts=[\"\"\"Natural language processing (NLP) refers to the branch of computer science—and more specifically, the branch of artificial intelligence or AI—concerned with giving computers the ability to understand text and spoken words in much the same way human beings can.\"\"\"]\n",
    "#pip install punk\n",
    "for text in texts:\n",
    "  sentences = nltk.sent_tokenize(text) #tokenize sentence\n",
    "  for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence) #tokenize words in each sentence\n",
    "    print(words)\n",
    "    #print(word)\n",
    "    #tagged=nltk.pos_tag(words)  #morphology -> tag set from Penn Treebank Tagset -> 45 tags \n",
    "    #print(tagged)\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "20643ba39cc192cecd775d36cbcb290681c3cfe28e501fd357f2d90d955dc5c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
