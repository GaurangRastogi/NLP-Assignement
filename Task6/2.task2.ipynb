{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "import pandas as pd\n",
    "df=pd.read_csv('./IMDB_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Data preparation\n",
    "# Remove html tags and (if required emojis)\n",
    "#Kaggle dataset is already cleaned, hence not recommended\n",
    "#Use a dataset and pre-process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming the Documents\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello!', 'how', 'are', 'you', 'do']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stemmer_tokenize(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "stemmer_tokenize(\"Hello! How are you doing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\GAURANG\n",
      "[nltk_data]     RASTOGI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#4 Vectorization of Documents\n",
    "tfidf=TfidfVectorizer(strip_accents=None,\n",
    "                      lowercase=False,\n",
    "                      tokenizer=stemmer_tokenize,\n",
    "                      use_idf=True,\n",
    "                      norm='l2',\n",
    "                      smooth_idf=True)\n",
    "\n",
    "Y=df.sentiment.values\n",
    "X=tfidf.fit_transform(df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 298135)\t0.06919594172775405\n",
      "  (0, 122704)\t0.06925466972673622\n",
      "  (0, 356809)\t0.02889561950368614\n",
      "  (0, 329126)\t0.04506530341289699\n",
      "  (0, 98199)\t0.022790243371972132\n",
      "  (0, 187709)\t0.01985988948388115\n",
      "  (0, 342256)\t0.11598635017472783\n",
      "  (0, 335518)\t0.06625581649735467\n",
      "  (0, 111180)\t0.06047287691356779\n",
      "  (0, 82740)\t0.03458453787077541\n",
      "  (0, 222098)\t0.034042229778458326\n",
      "  (0, 356474)\t0.03531231317519018\n",
      "  (0, 147037)\t0.10292730815064878\n",
      "  (0, 300322)\t0.05462847016241417\n",
      "  (0, 312063)\t0.05122494987494821\n",
      "  (0, 205334)\t0.03976236431956519\n",
      "  (0, 322705)\t0.023830442710942767\n",
      "  (0, 86620)\t0.07630496856021392\n",
      "  (0, 193073)\t0.02484043308612746\n",
      "  (0, 332977)\t0.03268927572351406\n",
      "  (0, 107464)\t0.050626218572446736\n",
      "  (0, 226456)\t0.04817660020052929\n",
      "  (0, 219313)\t0.10292730815064878\n",
      "  (0, 347641)\t0.027966952698494967\n",
      "  (0, 77199)\t0.03780803605571362\n",
      "  :\t:\n",
      "  (49999, 66627)\t0.03813544516853703\n",
      "  (49999, 327217)\t0.06882007047956079\n",
      "  (49999, 240304)\t0.0477338810346856\n",
      "  (49999, 157582)\t0.029175123964336656\n",
      "  (49999, 59909)\t0.06697792012046817\n",
      "  (49999, 242129)\t0.03357182283752254\n",
      "  (49999, 189364)\t0.02448778508035357\n",
      "  (49999, 287863)\t0.05463887374054041\n",
      "  (49999, 69187)\t0.04478708651793273\n",
      "  (49999, 194606)\t0.02548752499601533\n",
      "  (49999, 60652)\t0.041215241132846255\n",
      "  (49999, 223197)\t0.053375185945499296\n",
      "  (49999, 43620)\t0.03316328105789703\n",
      "  (49999, 351643)\t0.029669333472161073\n",
      "  (49999, 194035)\t0.09638110741461994\n",
      "  (49999, 323627)\t0.14446403929170237\n",
      "  (49999, 74317)\t0.06311828310035157\n",
      "  (49999, 81883)\t0.0320690052884827\n",
      "  (49999, 356525)\t0.08869050300722002\n",
      "  (49999, 199481)\t0.04066449324560111\n",
      "  (49999, 345972)\t0.04556246916248512\n",
      "  (49999, 322251)\t0.05344264825941679\n",
      "  (49999, 322501)\t0.2613161598323696\n",
      "  (49999, 244982)\t0.04544463010348064\n",
      "  (49999, 246874)\t0.03558927324694322 ['positive' 'positive' 'positive' ... 'negative' 'negative' 'negative']\n"
     ]
    }
   ],
   "source": [
    "print(X,Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Classification Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.5,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  6.1min finished\n"
     ]
    }
   ],
   "source": [
    "#5 Document Classification using logistic regression\n",
    "\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "clf=LogisticRegressionCV(cv=5,\n",
    "                         scoring='accuracy',\n",
    "                         random_state=0,\n",
    "                         n_jobs=1,\n",
    "                         verbose=2,\n",
    "                         max_iter=300).fit(X_train,Y_train)\n",
    "\n",
    "saved_model=open('saved_model.sav','wb')\n",
    "\n",
    "pickle.dump(clf,saved_model)\n",
    "saved_model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(Y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
